---
title: "Test Results"
format: html
editor: visual
---

#### Load Libraries

```{r, message=FALSE}
library(tidyverse)
library(janitor)
library(vembedr)
```

#### The Story

You test positive for a rare disease that only effects 0.001 (One in one thousand people).

So you ask the doctor:

-   How certain is it that I have this disease?

    -   The test correctly identifies 99% of people that have the disease and only incorrectly identifies 1% of people that don't have the disease

What are the chances that you actually have this disease?

-   Some would say 99%, the accuracy of the test

    -   What does bayes say?

$$
P(B \mid A) = \frac{P(B) L(B \mid A)}{P(A)} 
$$

B \<- Has Disease

A \<- Positive test result

P(B\|A) - The probability of having the disease given a positive test result

#### Simulate the Data

```{r}

set.seed(70)  # For reproducibility

# Parameters
n_patients <- 10000  # Total population size
n_diseased <- 10     # Number of patients with the disease
sensitivity <- 0.99  # True positive rate (sensitivity)
false_positive_rate <- 0.01  # False positive rate

# Step 1: Create the DataFrame with patients
patients <- data.frame(
  patient_id = 1:n_patients,
  has_disease = c(rep(1, n_diseased), rep(0, n_patients - n_diseased))  # 10 with the disease, rest without
)

# Shuffle the DataFrame to randomize patient order
patients <- patients %>%
  sample_frac(size = 1)

# Step 2: Simulate the test results based on disease status
patients <- patients %>%
  mutate(
    # Test result is positive if the person has the disease and the test is sensitive,
    # or if they don't have the disease but it's a false positive
    test_result = case_when(
      has_disease == 1 & rbinom(n_patients, size = 1, prob = sensitivity) == 1 ~ "positive",
      has_disease == 0 & rbinom(n_patients, size = 1, prob = false_positive_rate) == 1 ~ "positive",
      TRUE ~ "negative"
    )
  )




```

#### Apply Bayes Theorem in Class

B \<- Has Disease

A \<- Positive test result

sensitivity \* P(A\|B) / P(A)

```{r}
table(patients$has_disease, patients$test_result)
```

```{r}
patients %>% 
  tabyl(test_result, has_disease) %>% 
  adorn_percentages("col")
likelihood <- 1
```

```{r}
patients %>% 
  tabyl(test_result) %>% 
  adorn_percentages("col")
conditional <- .01
```

```{r}
prob <- .001
```

```{r}
0.001*1/.01
```

#### Video

```{r}
embed_url("https://www.youtube.com/watch?v=R13BD8qKeTg")
```

#### What about two positive test results?

$$
P(\text{have disease} \mid \text{positive second test}) = \frac{P(\text{have disease after first positive}) \cdot P(\text{positive second test} \mid \text{have disease})}{P(\text{positive second test})}
$$

Thoughts:

Having two positive results would potentially create two types of distribution or two types of datasets. One dataset is the first exercise where the samples have the columns of having_not_having_the_disease and positive_negative_test_results.

The second dataset will be created out of the population that tested positive. This second dataset would have a lesser sample which would potentially increase the value of the posterior.
